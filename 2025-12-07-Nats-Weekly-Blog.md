# Week 15 - Final Blog Post

## Project Summary and Outcomes:
This project was far more challenging than I anticipated. My original plan was to utilize mobile 3D scanning applications; however, the results were consistently bad, lacking details and large portions of the artifacts. Despite testing six different apps and following their instructions carefully, the apps all produced incomplete models, extensive smoothing (making the artifacts look like AI and lack any detail), and a lack of detail (roughness, wear and tear, texture, and designs). Many of the applications also required payment to export or to scan in general. After exhausting all of my options, I attempted to pivot to actual 3D scanners avaliable at the curation facility off campus.
## Scanner Limitations:
### PolyCam
This is the middle ground and this should be the best as it works with Lidar. You get 10 free scans before you have to pay. I find the scanning very difficult and not user friendly or understandable at all. However, this does include tutorial videos so that is very helpful. However, despite the tutorials, I have not actually been able to figure out how to scan more than just the top of the artifact.
### Capture
I found capture to be the most user friendly, free, and plausable. However, once you scan a couple times it asks you to pay, but does not make you pay to export. I am also having issues with the scans that although I am able to capture the tops, sides, and bottoms of the artifacts the details are REALLY lacking on the scans. You can see the shape and what the artifact is but nothing more indepth than that. I ultimatly decided to use this software for my 3D scans. This is because there are work arounds for the payment as you can delete previous scans you have exported to create more space for new ones. My main reason for choosing this was it was the best quality I could get and the work around for payment.
### Dot 3D
This was a disappointment once you try to scan you have to pay. 
### KIRI Engine 
Free app as far as I have been able to tell. Limit of scans once you get past a certain point. Works exactly the same as Capture, but no work around on the limit.
### Abound
This does not work without paying
### Scaniverse
This does not work without paying.
### Matter and Form 3D Scanner
This is the first 3D scanner I tried. While this was able to produce partial scans there were significant limitations:
- The scanner could not capture the bottom surfaces of artifacts (same problem I was having with the apps).
- Fine details were not recorded and instead appeared as blurred pixels.
- The scanner's software was so outdated that files could not be uploaded to any contemporary 3D viewing software I could find (Microsoft 3D, GIMP, Blender, or SketchFab).
- To scan a small artifact took roughly 30 minutes per artifact.

Image Below is 30+ minutes of scanning a complete artifact this is all that came out.

<img width="379" height="239" alt="image" src="https://github.com/user-attachments/assets/eb84e34d-da33-4aae-abf1-4bf9773adf5d" />


Because of these issues, the Matter and Form scanner was not a viable option for producing usable accessible models.
### Next Engine Desktop 3D Scanner
I also attempted to use the second scanner in the facility. This scanner is a newer more expensive model, so I thought there might have been a chance this could work. Unfortunatly, this device could not be powered on or connected to the SIU network, even with assistance. This left me without any functional 3D scanner options. So I pivoted back to the 3D scanning apps, which could at least produce some type of scan that could be uploaded to contemporary 3D viewing software.
## 3D Scanning Software and Application Limitations:
Returning to mobile applications, I ultimately selected Capture as the only app capable of producing somewhat usable scans. Even so, several challenges still remained.
- The bottom portions of artifacts did not scan in unless you could flip the object onto 3 different sides. (Almost impossible to find artifacts that can do this, not just front and back)
- White, clear, or reflective objects, such as glass, could not be captured.
- Most artifacts only had two scannable sides (front and back), but Capture required 3 or more positions to record the whole artifact.
- These restirictions significantly limited the range of artifacts I could include.
Because of these constraints, I selected several ceramic fragments that could be balanced on at least three sides. These fragments, however, had minimal contextual information beyond their provenience (Miller's Grove, Abby's Place, Unit 39.) This limited the interpretive depth I could provide in the final display. I checked the Miller Grove paper work, site information, unit forms, and other written materials provided along with the site paperwork. Additionally, I scanned and utilized three other artifacts in my final project (two whiteware plate fragments and one porcelain base fragment) to demonstrate decorative details or destructive archeological practice. Obtaining just these scans with the limited detail they provide required multiple attemptes, and the bottom of the surfaces could not be recorded.
## Software for Processing and Access:
### Sketch Fab
My intial plan was to construct a digital museum display using SketchFab. However, SketchFab does not allow users to combine multiple artifact scans into a cohesive exhibit. Though I was able to upload individual scans and annotate them, this platform alone could not support the level of integration I was looking for. This is the best option for uploading 3D scans. You are limited to 10 uploads per account on the free version. Luckily, my uncle is an engineer and was able to get me the pro for free because of his work. 
### Microsoft 3D Editor 
I did want to talk about Microsofts 3D editer a little bit. This doesn't work with too many things, and has very limited capabilites. If you just need to upload a 3D scan for personal use I would recommend this. If you are looking to make the scans accessible I would recommend SketchFab or Blender if you dedicate the time to learn it.
### Blender
Following my attempt to create a digital museum display in SketchFab I looked into Blender. Blender is completely free. Despite watching multiple tutorials, I found Blender too technically complex for the scope and timeline of this project. If I had dedicated at least 2 months to figuring out this software, I may have been able to figure it out. The software required a level of proficiency that I had not yet developed with it, making it impractical for me to continue working with it when I was not making any progress to further my project. However, I want to note that this is most likely the best option for a 3D interactive digital museum display. If someone dedicates a long time to figuring out this software they may be able to create something amazing on this.
<img width="1237" height="766" alt="image" src="https://github.com/user-attachments/assets/f0e0afd4-9f85-4b17-bd4d-fb0a8e86f708" />

## Alternative Solution: PowerPoint Digital Museum Display:
After exploring all of the above options, I emailed the CVEX lab at my university to see if they had a 3D scanner I could use. Unfortunatly, I got no reply. So I went in person when I had time and no one was there. As a final pivot, I created a digital museum display using PowerPoint.
- I photographed each artifact (front and back), using improvised studio conditions (see the image below). The curation center is missing its black professional backdrop.
- <img width="356" height="478" alt="image" src="https://github.com/user-attachments/assets/52dc71e7-4a48-4215-896f-6aa391e6eace" />

- I curated the images, context, and links to all SketchFab models into a single interactive slideshow.
- I created a SketchFab collection to group the scans and added annotations to each model.
This approach allowed to to present the artifacts cohesively despite the limitations of the scanning technologies. I was also able to use some of the skills I learned during the week we practice professional artifact photgraphy.
## Challenges Encountered:
This project required repeated pivots, and each stage presented unforeseen obstacles. This project was very difficult.
### Technical Limitations:
Incomplete scans, outdated scanners, software restrictions (Thanks University), and compatibility issues.
### Access Issues:
The unavailability of an appropriate photography backdrop required improvision. No answer from CVEX. Payments required for multiple softwares and apps. 
### Software Complexity:
Blender's rough learning curve limited my ability to produce a unified exhibit.
### Image Processing Issues:
Some photos in PowerPoint repeatedly distorted or flipped despite multiple attempts to correct them.
These challenges affected the final product and made it difficult to achieve the quality of work that I strive for.
## Reflection on Project Purpose and Process:

I chose this project because I wanted to challenge myself to learn new digital and anthropological skills, such as photogrammetry, 3D scanning, and SketchFab. However, I found that I learned most about what goes into digital curation and accessability. Throughout the semester, we discussed the importance of accessability, open access knowledge, and the role of digital tools in public archaeology and anthropology. This project ended up being just that. A way to develop and contribute something meaningful, but small, a digital museum display PowerPoint and 3D scans of 8 artifacts. This could, in theory, help make cultural heritage from Miller Grove more visible and accessible. In doing this project I also wanted to push myself to use new things such as SketchFab, 3D scanning apps, and possibly Blender, all of which have been used increasingly more in the field of anthropology. The process of creating this capstone project was far more complex than I initally expected. It was difficult, often frustrating, and required constant problem solving and pivoting when tools failed or porduced low quality results. There were moments (a lot in fact) when I did not enjoy the work simply because the outcomes never matched my standards or vision, but looking back, I appreciate how much I learned through those difficulties. It was not an easy project by any means, yet the challenges pushed me to think critically about what access really means in digital curation. In that way, the project deeply connected with course themes of accessability and open access, although I did not expect it to do that. I feel like I gained a lot of valuable insight into the realities of digital curation, public accessibility, and the labor involved in producing open access museum materials. I learned firsthand how cost barriers, outdated technology, and software limitations restrict what can be created and shared with the public. Despite these difficulties, I am proud of the adaptability, problem solving, and persistence I demonstrated. The final product reflects my best effort within the constraints I encountered. I also believe that the documentation of this process, on GitHub, may serve as a helpful guide for future students attempting similar work. By outlining what did and did not work, others may be able to build upon my experience and find solutions that were not available to me.


# Final Project
## 3D Scans
[SketchFab 3D Scans](https://skfb.ly/pE9Wx )
## PowerPoint
[Link to Digital Museum](https://saluki-my.sharepoint.com/:p:/g/personal/natalie_eves_siu_edu/IQBH9yV1W0WAS7YDoOrJelfTAS9KdYtpqiCyDECDon7QEew)


### Notable Mentions:
Attempt to 3D Scan a round button (Don't do it)


<img width="534" height="380" alt="image" src="https://github.com/user-attachments/assets/33062d88-e980-445d-abc3-d2196a5bbe88" />


Because all of the software or 3D scanning apps literally tell you to not do glass or shiny things. Of course I had to try. (They were right don't do it)


<img width="308" height="358" alt="image" src="https://github.com/user-attachments/assets/39188b9d-99bf-4bb3-b243-e796bdf4a2e4" />


